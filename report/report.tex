% !Mode:: "TeX:UTF-8"
\documentclass[10pt,a4paper,notitlepage]{report}
\usepackage{ifxetex,ifluatex}

% Better rendition of computer modern.
\usepackage{lmodern}

\usepackage{fontspec}
%\usepackage[utf8]{luainputenc}
\usepackage[utf8]{inputenc}

% For mathematical typesetting.
\usepackage{amsfonts,amsmath,amsfonts,amssymb}

% For formal grammar.
\usepackage{syntax}

% Provides an extended tabular environment.
\usepackage{tabularx}

% For images.
\usepackage{graphicx}
\usepackage{float}

% For better enumerations.
\usepackage{enumitem}

% For source code listings.
\usepackage{listings}

% For fancy captions.
\usepackage{caption}

% For hyperlinks and fancy citations.
\usepackage[colorlinks=true,linkcolor=black,citecolor=blue,urlcolor=blue]{hyperref}

% Setting page geometry.
\usepackage[left=4cm,right=2cm,top=2cm,bottom=2cm]{geometry}

% Sets spacing between paragraphs
\setlength{\parskip}{0.8em}

% Default caption form
\captionsetup{labelfont=bf,textfont=it,justification=centering,font=footnotesize}

% Shamelessly pinched from 'dbaupp'. cheers!
% http://tex.stackexchange.com/questions/51645/x86-64-assembler-language-dialect-for-the-listings-package
\lstdefinelanguage
    [x64]{Assembler}     % add a "x64" dialect of Assembler
    [x86masm]{Assembler} % based on the "x86masm" dialect
    {   % with these extra keywords:
        morekeywords={
            CDQE,CQO,CMPSQ,CMPXCHG16B,JRCXZ,LODSQ,MOVSXD,
            POPFQ,PUSHFQ,SCASQ,STOSQ,IRETQ,RDTSCP,SWAPGS,
            SYSCALL,
            rax,rdx,rcx,rbx,rsi,rdi,rsp,rbp,
            r8,r8d,r8w,r8b,r9,r9d,r9w,r9b
        }
    }

% Alias python [2] to python. Add missing yield
\lstdefinelanguage
    [2]{Python}
    []{Python}
    {
        morekeywords={yield}
    }

% Remove the print and exec statements from python to make python [3].
\lstdefinelanguage
    [3]{Python}
    []{Python}
    {
        morekeywords={yield},
        deletekeywords={print,exec}
    }

% Straight quotes, please.
%\lstset{upquote=true}
\lstset{basicstyle=\ttfamily}

\author{Elliot Thomas\\ \small Supervisor: Sean Tohill\\ \\ University of Westminster}
\title{Network Packet Capture Generation and Falsification}
\date{\today}

\begin{document}
\maketitle
\begin{abstract}
\begin{center}
A document describing the design and development of a tool to assist in the crafting of network packet captures for educational purposes.
\end{center}
\end{abstract}
\pagebreak
\tableofcontents

%%%%%%%%%%%%%%%%
% Introduction %
%%%%%%%%%%%%%%%%
\chapter{Introduction}
Education is important. Education is one of the underpinnings of a progressive society, along with law and order and a few other things.
Despite this, it seems human ingenuity is education's greatest enemy. Humans are lazy - most of us will strive to do as little work as possible for the greatest gain.
We seek to make our lives better, easier, all to spend more time on the things we enjoy. For many, this will be leisure activities, for some, socialising, the humble few may take joy in aulturism.
But motivations are irrelevant here, just the effects.
In academia, plagiarism is problem - people are unwilling to put the time in to do their own work. They realise that if someone else has solved a problem identical to theirs, they could just reuse that.
What these people fail to realise, is that there is no substitute for experience. This problem is relevant in all fields, academic or applied, practical or theoretical; computer security and forensics is no exception.

\section{Reader level}
The reader is expected to be somewhat familiar with networking terminology and forensic analysis techniques.

\section{The problem}
Teaching network security and forensics is aided greatly by the presentation of example packet captures. These are used to learn and practice analytical skills, and to assess the level of understanding and knowledge that students hold.
Creating such packet captures is not difficult, but there are few, if any tools available for automating the process. Changing this is the purpose of this project.

\pagebreak

\section{Existing Solutions}
None, it would seem.

There are a number of tools for network packet capture, and a number of tools for analysing them. These tools do not solve the problem \emph{per se}, but do allow packet capture manipulation to a certain extent, and therefore might be a useful aid in manipulating packet captures.

\subsection{editcap}
Editcap is a program distributed as part of Wireshark.\\
From the manpage\cite{editcap-man}:
\begin{quote}
\textbf{Editcap} is a program that reads some or all of the captured packets from the \underline{infile}, optionally converts them in various ways and writes the resulting packets to the capture \underline{outfile} (or outfiles).
\end{quote}

For the purposes of assisting generation, this program allows splitting a file into a series of files, according to the time they were sent; i.e., splitting every 2 seconds (where each set represents a packet capture and each number represents the time a packet arrived):\\
\indent (1, 1, 2, 3, 5, 7, 8) $\rightarrow$ (1, 1, 2), (3), (5), (7, 8)

\subsection{tshark}
Tshark is a program distributed as part of Wireshark.\\
From the manpage\cite{tshark-man}:
\begin{quote}
\textbf{TShark} is a network protocol analyzer. It lets you capture packet data from a live network, or read packets from a previously saved capture file, either printing a decoded form of those packets to the standard output or writing the packets to a file.  \textbf{TShark}'s native capture file format is \textbf{pcap} format, which is also the format used by \textbf{tcpdump} and various other tools.
\end{quote}

As stated, it acts as a network traffic capture and analysis tool. It has functionality that will identify packets by protocol (and can reconstruct TCP streams) and allows the user to filter them. This is useful functionality, as it allows you to remove packets from certain protocols making captures simpler to understand.

\subsection{Bit-Twist}
Bit-Twist is a tool suite containing a packet capture 'generator' (a traffic replay program, not unlike tcpreplay\cite{tcpreplay-web}) and a pcap editor.
From the website\cite{bittwist-web}:

\begin{quote}
With Bit-Twist, you can now regenerate your captured traffic onto a live network! Packets are generated from tcpdump trace file (.pcap file). Bit-Twist also comes with a comprehensive trace file editor to allow you to change the contents of a trace file.
\end{quote}

This tool is \emph{very} close to the desired utility. It permits editing a packet capture in a handful of ways, specifically:
\begin{itemize}
\item Appending a `payload' (arbitrary bytes) to the end of every packet.
\item Removing a range of bytes from every packet.
\item Recalculating checksums for (non-fragmented) IP, TCP, UDP and ICMP packets.
\item Saving a specific range of packets either by their occurance (i.e. The fourth packet to the seventh packet) or by their timeframe (i.e. all packets between 2006/10/1 00:00:00 and 2006/10/31 10:30:00).
\item Truncating packets to a specific 'layer' - where 2 is the link layer, 3 is the network layer and 4 is the application layer.
\item Restricting edits to a specific 'header'- Ethernet, ARP, IP, ICMP, TCP and UDP are supported in this case.
\end{itemize}

%%%%%%%%%%%%
% Research %
%%%%%%%%%%%%
\chapter{Research}
\section{Approaches to the Problem}
The problem `\emph{How does one generate unique packet captures for teaching analysis to students?}' is open to multiple solutions. In this project, three possible approaches were considered. These can be described as \emph{synthesis}, \emph{generation} and \emph{composition}.

\subsection{Synthesis}
This would work as a program that understands a \emph{scenario} defined in a kind of declarative language, that creates a set of unique permutations of that scenario by varying some key data (names, hosts, times etc.) and the exact sequence of events. From this, it would synthesise a complete packet capture from each scenario - carefully constructing every packet - such that all generated captures represent the same abstract event (i.e. corporate espionage) but with wildly different specifics, hindering collusion.

This approach has the advantage of a flexible interface and fast implementation - at the cost of having to understand and reproduce the complexity of various networking protocols and producing a completely artificial output.

\subsection{Generation}
Much like \emph{synthesis}, this would understand a declarative language for describing a scenario, but this approach would be to program a network of computers to actually do the actions in the scenario rather then synthesise their side effects. This would then run a packet sniffer on this network, generating perfectly authentic network captures of a real network, but where the human actors in a scenario are emulated by computers.

This approach has the advantage of flexibility and authenticity - at the cost of being very inefficient and fragile. It's more then likely such an approach would use a network of virtual machines running real-world operating systems and protocol implementations. This introduces a fair amount of unpredictability (which is both a good and bad thing), and would require changes if/when a used interface changes.

\subsection{Composition}
This was the first approach considered, and is perhaps the simplest. This would be a program that takes a set of existing packet captures (ideally, small purpose-built captures representing single transactions) and combines them while altering things like hosts, times and the like.

This approach has the advantage that real-world scenarios can be used - an existing library of captures will still be useful to provide a data source for the program - and it retains a degree of authenticity. It has a lesser variant of the downside that \emph{synthesis} has, in that it will need to identify and modify various networking protocols, but does not need to understand how they work - which removes a great deal of complexity. It also depends on existing captures - if these aren't available, the tool cannot function.

\subsection{Chosen Approach}
\emph{Synthesis} and \emph{generation} approaches are very complex - a good implementation would take a considerable amount of time to write and test, and allow a lesser degree of control to the user. For this reason, a \emph{composition} based approach was chosen - it is comparatively simple and easy to understand; desirable qualities for any tool.

% Programming language criteria
\section{Programming language: Criteria}
Choosing a programming language is, obviously, a decision that needs to be made, and there is no single correct choice. There are many factors influencing such a decision, each one needs to be considered. There were three major factors considered in this decision: requirements - what does the program require? knowledge - how difficult will it be to program in and maintain? availability - on what platforms can projects using this language be used?

\subsection{Requirements influence}
At it's heart, this project is a data processing project. There are no requirements for real-time processing, no requirements for concurrency, no requirement to make use of or implement a specific API nor requirements for any kind of interactive behaviour. This project can very easily be designed and implemented as a batch program - give input, run program, get output.

Given the minimalistic requirements of the program, just about any Turing-complete language is serviceable. As such, the decision will have to be made predominantly on the other three factors. That's not to say entirely, some languages lend themselves quite well to generic data manipulation, while others are more specialised and geared towards specific purposes. For instance, Javascript is more suited towards web-based projects (given that it's usual interpreter is a web browser), while C, Java and Python are more general purpose. Haskell, Java and Python have good support for abstract data structures while various assembly languages barely have the notion of a data type.

One important factor is for the program to be easily extended. While it is possible to write an extendible program in just about any language, it helps considerably if there is support for loading code from an external source at runtime, i.e. to allow building a plugin architecture.
Most languages or platforms allow this in some manner (and practically all platforms depend on doing this in one way or another - this is how shared libraries work). While POSIX platforms provide functions like \lstinline$void *dlopen(const char *filename, int flag);$, this interface isn't consistently available on non-POSIX platforms, and requires code to be compiled first. Meanwhile, Python, Javascript and even Bash provide methods for loading new code programatically without the need to compile code first, allowing for a very flexible, powerful and user-friendly system to be developed.

\subsection{Knowledge influence}
Knowledge is a subjective factor that pertains to the programmer(s) developing the project. It is a limiting factor; a programmer proficient in C is not necessarily going to be able to understand a very different language such as Haskell. Also worth mentioning is simple preference - while not a overriding factor - can help shape a choice.

\subsection{Availability influence}
Availability for most languages is somewhat of a non-issue. Given that portability is a desirable outcome, only languages which have a usable and consistent enough implementation across platforms will be considered. This eliminates some languages such as C\#, Visual Basic (or any .NET language).

It is also worth noting portability - are there provisions for file input/output? In the case of the various assembly languages, this is left to the programmer. Even if the assembly language itself is abstract and portable, it only dictates how the processor is used - assembly often leads to some \emph{very} specific code.

\begin{lstlisting}[
	language={[x64]Assembler},captionpos=b,
	caption={[64-bit assembly example]Written for x86-64 processors, this uses Linux's 64-bit system call convention to write data to 'stdout' (standard output)}
	]
mov rax, 1   ; system call constant for write on Linux64
mov rdi, 1   ; first argument: file descriptor to write to, eg: stdout.
mov rsi, msg ; second argument: buffer holding data to be written.
mov rdx, len ; third argument: number of bytes to write.
syscall      ; Do the system call. Similair to int 0x80.
\end{lstlisting}

\section{Programming Language: Assessment}
It should be noted that many languages were discarded based on the author's knowledge. % TODO

\subsection{Chosen Language}
Time was the unspoken major factor in this decision, and given the liberty to choose any programming language means ones in which the programmer has experience will take precedence. This means that languages designed for unfamiliar paradigms (such as Haskell, being a purely functional programming language\cite{haskfunc}) or languages that leave a considerable amount of work to their user (such as Assembly) were eliminated.

The choice was Python. This was driven by it's status as a multi-paradigm language that offers a different models of program abstraction.
To illustrate this, below are two functionally equivalent and compatible prime number \emph{iterators};
\begin{lstlisting}[
	language={[3]Python},label={lst:ooprime},
	caption={[Python primegen, object style]An object oriented approach to a prime generator.}
]
class primegen:
    def __init__(self, start, end):
        self.cur = start
        self.lim = end

    def __iter__(self):
        return self

    def __next__(self):
        prime = False
        while not prime:
            if self.cur >= self.lim:
                raise StopIteration()
            for i in range(2, self.cur/2):
                if self.cur % i == 0:
                    break
            else:
                retval = self.cur
                prime = True
            self.cur += 1
        return retval
\end{lstlisting}

\begin{lstlisting}[
	language={[3]Python},label={lst:ooimp},
	caption={[Python primegen, imperative style]An imperative approach to a prime generator.}
]
def primegen(cur, lim):
    while cur < lim:
        for i in range(2, cur/2):
            if cur % i == 0:
                break
        else:
            yield cur
        cur += 1

\end{lstlisting}

\subsection{Python 2 or Python 3?}
Like most languages, Python has versions. The Python language currently exists as two distinct versions, Python 2 and Python 3. This is not to be confused with the multiple implementations of Python - which can support the same language and standard library - but the actual grammar of the language.

\subsubsection{What is wrong with Python 2?}
As a language, Python 2 made some odd decisions. Firstly, it had a `print' statement - which sounds perfectly reasonable until you need to accommodate for edge cases and specific behaviour. Print statements have the form;
\begin{grammar}
<expressions> ::= <expression> | <expression> `,' <expressions>

<print statement> ::= `print' <expressions>
\alt `print' <expressions> `,'
\end{grammar}

which means that
\begin{lstlisting}[language={[2]Python}]
print "a", "b", "c"
\end{lstlisting}

is distinct from
\begin{lstlisting}[language={[2]Python}]
print "a", "b", "c",
\end{lstlisting}

The former outputting ``a b c'' followed by a newline, and the latter outputting ``a b c'' without a newline! There is no convenient way of changing what the item separator is, requiring setting a field in the `sys' module. The exec statement has similar issues.

Furthermore, Python 2 has some odd semantics for it's `input' function, which will read a line of standard input, and then \emph{evaluate this input as a Python expression}. In order to read the unevaluated input, `raw_input' is needed.

Python 2 evolved in such a way to have two different object orientation systems. Python 2 has \emph{old-style} classes and \emph{new-style} classes, observe:

\begin{lstlisting}[language={[2]Python}]
>>> class Foo:
...  pass
... 
>>> class Bar:
...  pass
... 
>>> class Quux(object):
...  pass
... 
>>> f = Foo()
>>> b = Bar()
>>> q = Quux()
\end{lstlisting}

Here, two (empty) \emph{old-style} classes `Foo' and `Bar' are defined, along with a \emph{new-style} class `Quux'. Instantiation is identical for all of them, however...

\begin{lstlisting}[language={[2]Python}]
>>> type(f)
<type 'instance'>
>>> type(b)
<type 'instance'>
>>> type(q)
<class '__main__.Quux'>
\end{lstlisting}

Their \emph{type} differs. All \emph{old-style} objects have a type of `instance' while \emph{new-style} objects have a type matching their class.

\begin{lstlisting}[language={[2]Python}]
>>> type(f) == type(b)
True
>>> type(f) == type(q)
False
\end{lstlisting}

Python 2 also shares a limitation common to early, ``lower level'' programming languages like C in that it does not distinguish between a \emph{string of characters} and a \emph{string of bytes}.
This makes handing either somewhat cumbersome. For instance,

\begin{lstlisting}[
    language={[2]Python},
    caption={[Python 2 character length] The pound sign, with a length of two characters.}
]
>>> len("£")
2
\end{lstlisting}

Which makes sense only when considered as a UTF-8 encoded characer, which exists as $(194, 163)$ representing codepoint $163$ in unicode.
Python 3 provides a better abstraction - strings are arrays of characters, `bytes' are arrays of integers in the range $0 \rightarrow 255$, and strings can be encoded to bytes using a variety of different encodings.

\begin{lstlisting}[
    language={[3]Python},
    caption={[Python 3 character length] The pound sign, with a length of one character.}
]
>>> len("£")
1
\end{lstlisting}

This is a rather important and useful distinction when dealing with predominantly binary data such as captured packets.

Perhaps the most compelling reason is that the reference implementation, CPython, currently exists as CPython 2.7 and CPython 3.4, with 2.7 being in maintenance mode\cite{cpy2maint} - that is, bug fixes only.

\section{Architecture}
There are many different ways of categorising programs, but most programs have a important, distinctive piece of behaviour that can place a program in one of two mutually exclusive categories. That is, are they \emph{interactive} or not.

In the context of program design, an interactive program is one that accepts and alters it's behaviour based on human input.
A prime example of an interactive program is a text editor - it accepts input in the form of a series of keyboard presses and interprets each of these as a command to write a corresponding character.

Conversely, a non-interactive program is one that does \emph{not} accept user input. For instance, a compiler is generally non-interactive - it takes input in the form of source code, and produces output in the form of compiled code.

The author, being a Linux aficionado, is particularly fond of following the \emph{UNIX philosophy} where appropriate. This philosophy has no formal definition, but was once summarised, in the words of Peter H. Salus\cite{qcou},
\begin{quote}
This is the Unix philosophy: Write programs that do one thing and do it well. Write programs to work together. Write programs to handle text streams, because that is a universal interface.
\end{quote}

To this end, a system based around multiple small utilities that can be strung together to produce the desired output seems an appropriate architecture.

\section{Development Methodology}
The widely known `waterfall model' of software development was, in it's current form, presented as a flawed model that lacked development stage feedback\cite{wwr-waterfall-notes}. It represents an idealised scenario where all requirements are specific, well understood and concrete, and that there are no unforeseen problems in implementation. Unfortunately, this is not how things work in practice.

As the project will consist of lots of small components, with a tree-like dependency graph, it is possible to design, build and test sets of components, without having designed a complete system. This is called \emph{prototyping}, and is a practical approach to designing small systems.
Doing this repeatedly to build a larger system is known as \emph{incremental development}, and is essentially concurrent application of the waterfall model. Doing any design methodology repeatedly is called \emph{iterative development}.

Ultimately, a prototype driven iterative and incremental development model seems like the most appropriate approach.

\section{Libraries}
The use of external libraries was considered for understanding file formats - namely libpcap, a C library, which supports the ubiquitous pcap file format.

Python supports a FFI (Foreign Function Interface) module for C libraries under the name `ctypes' and supports understanding C-like data structures using the `struct' module, so this itself isn't a limiting factor.
However, existing bindings are outdated or are for Python 2, so a new set of bindings would have to be written. Libpcap does not have a very complex interface, but a lot of the functionality of libpcap is irrelevant - functionality related to querying network devices and capturing their output is not needed. The effort required to make a proper set of library bindings exceeds the effort to reimplement the desired functionality in pure python.

Instead, the documentation for libpcap's file format was used. This will be discussed later.

%%%%%%%%%%%%%%%%
% Requirements %
%%%%%%%%%%%%%%%%
\chapter{Requirements}
\section{Functional Requirements}

\begin{enumerate}[label=\bfseries FR\arabic*:]
\item \label{fr:1} The program shall be able to read a packet capture file in at least pcap format as program input.
\item \label{fr:2} The program shall be able to write a packet capture file in at least pcap format as program output.
\item \label{fr:3} The program shall be able to identify protocols used in individual packets, and based off this information should...
\item \label{fr:4} ... be able to selectively remove packets belonging to a predefined set of protocols.
\item \label{fr:5} ... be able to alter the contents of packets based on a set of predefined substitutions.
\item \label{fr:6} The program shall be able to accept multiple inputs, and merge them into a single output.
\item \label{fr:7} The program shall be able to alter the timestamp metadata for individual packets.
\item \label{fr:8} The program shall allow for externel support code (extensions) for handling new protocols to be added and used at runtime.
\item \label{fr:9} The program shall be able to operate on streaming data in addition to static files.
\end{enumerate}

\section{Non-functional Requirements}

\begin{enumerate}[label=\bfseries NFR\arabic*:]
\item \label{nfr:1} The program shall be useable on any python implementation supporting at least Python 3.4.
\item \label{nfr:2} The program shall be usable on any platform supported by such an implementation.
\item \label{nfr:3} The program should scale well and have, as a worst case, a small coefficient linear memory usage growth rate in respect to input data size.
\item \label{nfr:4} The program should scale well and have a linear time complexity in respect to input data size.
\item \label{nfr:5} The program's source code shall be designed in a maintainable manner, such that...
\item \label{nfr:6} ... irreleant components make no assumptions about the input file format.
\item \label{nfr:7} ... irreleant components make no assumptions about the output file format.
\item \label{nfr:8} ... support for identifying new protocols requires few, if any alterations to existing code.
\item \label{nfr:9} ... support for new file formats requires few alterations to existing code.
\item \label{nfr:10} The program (and it's source code) should be structured and reusable with-well defined interfaces.
\item \label{nfr:11} The program should be resilient - it should handle invalid data gracefully.
\item \label{nfr:12} The program should be secure - it should handle malicious data in a safe way.
\end{enumerate}

%%%%%%%%%%
% Design %
%%%%%%%%%%
\chapter{Design}
\section{Architecture}

\chapter{Appendix}
\section{Formats}
Pcap file format.


%%%%%%%%%%%%%%%%
% Bibliography %
%%%%%%%%%%%%%%%%

\begin{thebibliography}{99}
\bibitem{editcap-man}
    Richard Sharpe, Guy Harris, Ulf Lamping (4th of March, 2015)\\
    EDITCAP (1), The Wireshark Network Analyzer

\bibitem{tshark-man}
    Gerald Combs, numerous others (4th of March, 2015)\\
    WIRESHARK (1), The Wireshark Network Analyzer

\bibitem{tcpreplay-web}
    Aaron Turner, Fred Klassen\\
    tcpeplay home page(s).
    \url{http://tcpreplay.appneta.com}\\
    (see also: \url{http://tcpreplay.synfin.net/})

\bibitem{bittwist-web}
    Addy Yeow Chin Heng\\
    libpcap-based Ethernet packet generator.\\
    \url{http://bittwist.sourceforge.net/}

\bibitem{haskfunc}
    Simon Peyton Jones (December, 2014)\\
    The Haskell 98 Report\\
    \url{https://www.haskell.org/onlinereport/intro.html}

\bibitem{cpy2maint}
    Various authors (13th of April, 2014)\\
    Should I use Python 2 or Python 3 for my development activity?\\
    \url{https://wiki.python.org/moin/Python2orPython3}

\bibitem{qcou}
    Peter H. Salus. (1st of June, 1994)\\
    A Quarter-Century of Unix

\bibitem{wwr-waterfall-notes}
    Dr. Winston W. Royce (26th August, 1970)\\
    MANAGING THE DEVELOPMENT OF LARGE SOFTWARE SYSTEMS\\
    \url{http://www.cs.umd.edu/class/spring2003/cmsc838p/Process/waterfall.pdf}
\end{thebibliography}
\end{document}
